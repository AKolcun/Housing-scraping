{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "import googlemaps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\ajk51\\Desktop\\Apartment Search\\chromedriver\"\n",
    "ser = Service(path)\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "driver  = webdriver.Chrome(service = ser, options=options)\n",
    "driver.get(\"https://www.furnishedfinder.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enters city and selects max budget option to pull in all options.\n",
    "\n",
    "city = input('Enter destination city, state')\n",
    "\n",
    "search  = driver.find_element(By.ID,'where')\n",
    "search.send_keys(city)\n",
    "\n",
    "budget = Select(driver.find_element(By.ID, 'maxbudget'))\n",
    "budget.select_by_visible_text('$3,400+')                                   \n",
    "\n",
    "go = driver.find_element(By.ID, 'Go')\n",
    "go.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Deselect room&hotel options, select pet friendly. Extract page state at that time, and create soup object\n",
    "\n",
    "room = driver.find_element(By.ID, 'Shared1')\n",
    "hotel = driver.find_element(By.ID, 'Hotel1')\n",
    "pets = driver.find_element(By.XPATH,'//*[@id=\"ctl00_ContentPlaceHolder1_divRowFilter\"]/div/div/div[4]/label')\n",
    "#view = driver.find_element(By.CLASS_NAME, 'map_view')\n",
    "\n",
    "#view.click()\n",
    "room.click()\n",
    "time.sleep(1)\n",
    "hotel.click()\n",
    "time.sleep(1)\n",
    "pets.click()\n",
    "\n",
    "time.sleep(15) #Required for proper function. Page needs some time to load in assets\n",
    "\n",
    "page_source = driver.page_source\n",
    "soup = bs(page_source, 'lxml')\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds and stores all listings, identified under 'table_container' class. Results dict initialized, then ID #'s\n",
    "#and blurb info pulled from listings.\n",
    "\n",
    "results = soup.find_all('div', class_='table_container')\n",
    "key_list = []\n",
    "\n",
    "for item in results:\n",
    "    key_list.append(item.find(id=True).get('id')[1:])\n",
    "\n",
    "cols = ['Property Type', 'Bedrooms', 'Rent', 'Utilities Included', 'Min Stay', 'Bathrooms', 'Fees', 'Yard', 'Parking']\n",
    "listings = pd.DataFrame(index=key_list, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_details(prop_id):\n",
    "    '''Using ID number, navigate to details page for property and extract data to fill dataframe\n",
    "        Returns 9 values'''\n",
    "    try:\n",
    "        url = F\"https://www.furnishedfinder.com/property/{prop_id}\"\n",
    "        page = requests.get(url, 'lxml')\n",
    "        soup = bs(page.text)\n",
    "\n",
    "        tags = soup.find_all(class_='display_property')\n",
    "\n",
    "        property_type = soup.find(name='label', text='Type').parent.div.text.strip()\n",
    "\n",
    "        min_stay = soup.find(name='label', text='Minimum Term').parent.div.text.strip()\n",
    "\n",
    "        bedrooms = soup.find(name='label', text='Bedrooms').parent.div.text.strip()[0]\n",
    "        if bedrooms.isalpha(): #Classifies studio apts as 0.5 bedroom\n",
    "            bedrooms = '0.5'\n",
    "\n",
    "        bathrooms = soup.find(name='label', text='Bathrooms').parent.div.text.strip()[0]\n",
    "\n",
    "        if 'Yes' in soup.find(name='label', text='Utilities Included?').parent.text:\n",
    "            util_included = True\n",
    "        else:\n",
    "            util_included = False\n",
    "\n",
    "        rent = soup.find(id='price1Div').text.strip().strip('$')\n",
    "\n",
    "        try:\n",
    "            fees = soup.find(name='h3', text=re.compile('Property Fees')).parent.parent.ul.get_text(strip=True, separator='/')\n",
    "        except:\n",
    "            fees = None\n",
    "\n",
    "        parking = re.search('[\\w ]*[pP]arking[\\w ]*', str(soup.find(class_='AccList'))) #Searches 'Accomodations'\n",
    "        if parking == None:\n",
    "            parking == False\n",
    "        else:\n",
    "            parking = parking.group().strip()\n",
    "\n",
    "        if re.search('[yY]ard', soup.find(id='collapseOne3').p.text)== None: #Searches property description\n",
    "            yard = False\n",
    "        else:\n",
    "            yard = True\n",
    "\n",
    "        return property_type, bedrooms, rent, util_included, min_stay, bathrooms, fees, yard, parking\n",
    "    \n",
    "    except:\n",
    "        print(F\"Extract details failure on {prop_id}\")\n",
    "        property_type, bedrooms, rent, util_included, min_stay, bathrooms, fees, yard, parking = ['ERR'] * 9\n",
    "        \n",
    "        return property_type, bedrooms, rent, util_included, min_stay, bathrooms, fees, yard, parking\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_availability(prop_id):\n",
    "    '''Using ID number, navigates to availability page for property and extracts \"Not available\" dates\n",
    "    Webdriver required to navigate into iframe'''    \n",
    "    \n",
    "    try:\n",
    "        options = Options()\n",
    "        options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        options.add_experimental_option('useAutomationExtension', False)\n",
    "        options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "        options.headless = True\n",
    "        driver  = webdriver.Chrome(service = ser, options=options)\n",
    "        driver.get(F\"https://www.furnishedfinder.com/property/{prop_id}/avail\")\n",
    "\n",
    "        frame = driver.find_element(By.TAG_NAME, 'iframe')\n",
    "        driver.switch_to.frame(frame)\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        scripts = driver.find_elements(By.TAG_NAME, 'script')\n",
    "        avail = scripts[-3].get_attribute('outerHTML')\n",
    "\n",
    "        check = re.findall(\"(?:Not Available.*?start:.*?)(\\d{4}-\\d{2}-\\d{2})(?:.*?)(\\d{4}-\\d{2}-\\d{2})\", avail)\n",
    "        driver.close()\n",
    "\n",
    "        return check\n",
    "    \n",
    "    except:\n",
    "        print(F\"Find availability failure on {prop_id}\")\n",
    "        return 'ERR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coordinates(prop_id):\n",
    "    '''Using ID number, navigates to location page and extracts lat & lon data'''\n",
    "\n",
    "    try:\n",
    "        url = F\"https://www.furnishedfinder.com/property/{prop_id}/loc\"\n",
    "        page = requests.get(url, 'lxml')\n",
    "        loc_soup = bs(page.text)\n",
    "\n",
    "        text = str(loc_soup(attrs={'data-js-optimize':'minify'})[0]) #Should always return one match\n",
    "\n",
    "        return re.search('(?:{center: new google.maps.LatLng\\()(.*)(?:\\))',  text)[1].split(', ')\n",
    "    \n",
    "    except:\n",
    "        print(F\"Extract coords failure on {prop_id}\")\n",
    "        return \"ERR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Extract data from listings and filter\n",
    "\n",
    "listings = listings.apply(lambda x: extract_details(x.name), axis =1, result_type='expand')\n",
    "\n",
    "listings.rename(columns=dict(zip(range(9), cols)), inplace=True)   \n",
    "\n",
    "listings['Availability'] = listings.apply(lambda x: find_availability(x.name), axis=1)\n",
    "listings['Location'] = listings.apply(lambda x: extract_coordinates(x.name), axis=1)\n",
    "listings['Link'] = listings.apply(lambda x: F\"https://furnishedfinder.com/property/{x.name}\", axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dates(row):\n",
    "    '''Designed for use on a series. Checks and adds tuples of dates to results if today\"s date is between them'''\n",
    "    results = []\n",
    "    today = dt.date.today()\n",
    "    \n",
    "    for entry in row:\n",
    "        start = date.fromisoformat(entry[0])\n",
    "        end = date.fromisoformat(entry[1])\n",
    "\n",
    "        if (start < today < end or today < start):\n",
    "            results.append(entry)\n",
    "            \n",
    "    return results\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def availability_mask(row, start_date, end_date):\n",
    "    \n",
    "    for entry in row:\n",
    "        res_start = date.fromisoformat(entry[0])\n",
    "        res_end = date.fromisoformat(entry[1])\n",
    "        \n",
    "        if (job_start < res_start < job_end or job_start < res_end < job_end):\n",
    "            return False\n",
    "        \n",
    "        if  (res_start < job_start < job_end or res_start < job_end < res_end):\n",
    "            return False\n",
    "        \n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deletes records with ERR entries, removes extraneous reservation data, cleans Rent columns.\n",
    "\n",
    "listings = listings[listings['Availability'] != 'ERR']\n",
    "\n",
    "listings['Availability'] = listings['Availability'].apply(filter_dates)\n",
    "\n",
    "listings.to_pickle(input('Enter name for pickle file')+ '.pkl')\n",
    "\n",
    "job_start = dt.datetime.strptime(input('Start date, YYYY, MM, DD'), '%Y, %m, %d').date()\n",
    "job_end = dt.datetime.strptime(input('End date, YYYY, MM, DD'), '%Y, %m, %d').date()\n",
    "\n",
    "listings['Is Available'] = listings['Availability'].apply(availability_mask, args=(job_start, job_end))\n",
    "listings = listings[listings['Is Available'] == True]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google API Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#googlemaps API\n",
    "#First, setup googlemaps object with API key, define work position, and pick departure time.\n",
    "\n",
    "geolocator = googlemaps.Client(key='AIzaSyCGlQ7vlXIpzq9ngfd1Eoro9ERdKzcGmtM')\n",
    "work = (input('lat, lon of work'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run apply across all rows, using lat and lon values from each listing. RUN ONLY ONCE\n",
    "\n",
    "listings['Time To Work'] = (listings.apply(lambda x: \n",
    "                           geolocator.directions((x['Location']), work, #directions requires lat & lon tuples\n",
    "                             mode='driving', departure_time=job_start)\n",
    "                           [0]['legs'][0]['duration_in_traffic']['value'] ,axis=1)) #indexing into the records get drive time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean rent column and export to csv for use in Data Studio. Overwrite pickle file with updated listings data\n",
    "\n",
    "listings.to_pickle(input('Name for final pickle file') + '.pkl')\n",
    "\n",
    "listings['Rent'] = listings['Rent'].str.strip('/Month')\n",
    "listings['Rent'] = listings['Rent'].str.slice(stop=5).str.slice_replace(start=1, stop=2)\n",
    "listings['Location'] = listings['Location'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "listings.to_csv(input('File name for csv export') + '.csv', index_label='ID')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
